<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Jiale Wang â€“ Video Portfolio</title>

  <style>
    body {
      margin: 0;
      background: #1f1f1f;
      font-family: Arial, sans-serif;
      color: #fff;
    }

    .header {
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 50px 20px;
      gap: 40px;
    }

    .photo {
      width: 220px;
      height: 220px;
      border-radius: 10px;
      object-fit: cover;
      border: 4px solid #fff;
      box-shadow: 0 4px 16px rgba(0,0,0,0.4);
    }

    .info-box {
      max-width: 450px;
    }

    .name {
      font-size: 42px;
      font-weight: 700;
      margin: 0 0 20px 0;
    }

    .contact {
      font-size: 18px;
      line-height: 32px;
      margin-bottom: 20px;
    }

    .contact a {
      color: #ff8dd6;
      text-decoration: none;
      font-weight: bold;
    }

    .about {
      font-size: 17px;
      line-height: 26px;
      color: #ddd;
    }

    .content {
      max-width: 900px;
      margin: 0 auto;
      padding: 20px;
    }

    h2 {
      margin-top: 40px;
      border-left: 4px solid #ff8dd6;
      padding-left: 10px;
      font-size: 24px;
    }

    .section-title {
      margin-top: 30px;
      font-size: 32px;
      font-weight: bold;
      padding-bottom: 10px;
      border-bottom: 2px solid #444;
      color: #ff8dd6;
    }

    .tab-container {
      margin-top: 20px; 
      display: flex; 
      gap: 20px;
    }

    .tab-button {
      cursor: pointer;
      font-size: 20px;
      font-weight: bold;
      padding: 10px;
      border-bottom: 3px solid transparent;
    }

    .tab-button.active {
      border-bottom: 3px solid #ff8dd6;
    }

    @media (max-width: 700px) {
      .header {
        flex-direction: column;
        text-align: center;
      }
      .info-box {
        text-align: center;
      }
    }
  </style>
</head>

<body>

  <!-- HEADER -->
  <div class="header">
    <img 
      class="photo" 
      src="https://raw.githubusercontent.com/David-bit-jpg/davidwjl.github.io/main/me.jpg"
      alt="Jiale Wang Photo"
    >

    <div class="info-box">
      <div class="name">Jiale Wang</div>

      <div class="contact">
        ðŸ“§ jialewan@usc.edu<br>
        ðŸ”— <a href="https://github.com/David-bit-jpg" target="_blank">GitHub</a>
      </div>

      <div class="about">
        Computer Science Games major and Artificial Intelligence Applications minor at the University of Southern California. 
      </div>
    </div>
  </div>

  <!-- CONTENT -->
  <div class="content">

    <!-- TABS -->
    <div class="tab-container">
      <div class="tab-button active" onclick="showTab('research')" id="researchTab">Research Projects</div>
      <div class="tab-button" onclick="showTab('graphics')" id="graphicsTab">Graphics Projects</div>
      <div class="tab-button" onclick="showTab('games')" id="gamesTab">Game Projects</div>
    </div>

    <!-- ====================== RESEARCH ====================== -->
    <div id="research">

      <div class="section-title">Research Projects</div>

      <!-- Project 1 -->
      <h2>Multimodal UAV Simulation Benchmark</h2>
      <p style="color:#ccc; font-size:16px; line-height:24px;">
        We designed and implemented the complete multimodal simulation and data-generation pipeline for a 3D UAV perception
        benchmark built on the UE4-based CARLA engine. This pipeline integrates realistic UAV flight dynamics, synchronized
        multi-sensor acquisition, cross-modal timestamp alignment, and unified coordinate transformation, enabling large-scale
        generation of geometrically consistent RGB, LiDAR, radar, and DVS data across diverse scenes and weather conditions. As
        an extension to the core pipeline, I developed a virtual infrared post-processing module that recreates sensor-level IR
        characteristics absent in CARLA, allowing efficient production of high-quality thermal imagery at scale. The final
        dataset contains over 400K spatio-temporally aligned frames with 2D/3D bounding boxes, 6-DoF poses, and instance
        identities, providing a comprehensive foundation for multimodal UAV perception and trajectory prediction research.
      </p>

      <div style="margin-top:20px;">
        <iframe 
          src="https://drive.google.com/file/d/1CEAs879mZJNzco0JfyKbrDyAbU8xD8xP/preview"
          width="100%" height="430" allow="autoplay"
          style="border:none; border-radius:10px;">
        </iframe>
      </div>
            <p style="margin-top:15px;">
              ðŸ“„ <a href="https://arxiv.org/pdf/2511.22404" target="_blank"
                style="color:#ff8dd6; font-weight:bold; text-decoration:none;">
                Paper
              </a>
            </p>
      <!-- Project 3: Reinforcement Learning Agent for Junqi -->
      <h2>Reinforcement Learning Agent for Junqi</h2>
      
      <p style="color:#ccc; font-size:16px; line-height:24px;">
        In this project, I developed a reinforcement learning (RL) agent for Junqi (Chinese Army Chess), a complex board game
        requiring long-horizon planning amid hidden information. I formulated the game as a RL problem and adapted Deep
        Q-Networks (DQN) to tackle its core challenges: partial observability, a large action space, and sparse, delayed
        rewards. My key contributions included designing a compact state representation, a shaped reward function to promote
        strategic exploration, and training a DQN agent that learned competitive policies from incomplete information. A
        notable
        outcome was the agent's emergent ability to determine the optimal timing for switching between offensive and defensive
        strategies, resulting in robust and adaptive performance. This project offers a systematic analysis of deep RL in
        hidden-state environments and demonstrates how DQN-based agents cultivate strategic behaviors under uncertainty.
      </p>
      
      <div style="margin-top:20px;">
        <iframe src="https://drive.google.com/file/d/1O1HDGR8QZdmWwQyw9c_4ZvriL9VYLT8x/preview" width="100%" height="430"
          allow="autoplay" style="border:none; border-radius:10px;">
        </iframe>
      </div>
      
      <p style="margin-top:15px;">
        ðŸ“„ <a href="https://drive.google.com/file/d/1PdsWOLg6sktb99i5chdBIV8Ci2HvJquA/view" target="_blank"
          style="color:#ff8dd6; font-weight:bold; text-decoration:none;">
          Technical Report
        </a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        ðŸ”— <a href="https://github.com/David-bit-jpg/Reinforcement-Learning-JunQi" target="_blank"
          style="color:#ff8dd6; font-weight:bold; text-decoration:none;">
          GitHub Repository
        </a>
      </p>

      <!-- Project 2: Avalon Multi-Agent Reasoning -->
      <h2>Multi-Agent Strategic Reasoning for Avalon</h2>

      <p style="color:#ccc; font-size:16px; line-height:24px;">
          This project investigated the adaptation of large language models (LLMs) for complex, multi-agent strategic reasoning in
          environments of imperfect information, using the social deduction game Avalon as a testbed. My independent work centered
          on orchestrating multiple LLM agents by developing a novel framework that assigned personality-conditioned prompts and
          implemented cognitive mechanisms for memory and belief updating. I fine-tuned Llama-3 models to adhere to role-specific
          behavioral priors and engineered a structured internal state to track game history and infer hidden player alignments.
          The resulting agent cohort successfully executed complete game cycles, exhibiting stable and belief-consistent strategic
          behaviorsâ€”including negotiation and collaborationâ€”despite inherent information asymmetry. This work underscores my
          ability to formulate and execute a full-cycle research project at the intersection of NLP and multi-agent systems.
      </p>

      <div style="margin-top:20px;">
        <iframe src="https://drive.google.com/file/d/1ut9XQXAbda-gNBl8nv-LALVpcNsQLimi/preview" width="100%" height="430"
          allow="autoplay" style="border:none; border-radius:10px;">
        </iframe>
      </div>

      <p style="margin-top:15px;">
        ðŸ“„ <a href="https://drive.google.com/file/d/1b4ibszCBtZLhQ36TEnS4-4YEx0VU_2Ar/view" target="_blank"
          style="color:#ff8dd6; font-weight:bold; text-decoration:none;">
          Technical Report
        </a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        ðŸ”— <a href="https://github.com/David-bit-jpg/Avalon-agent" target="_blank"
          style="color:#ff8dd6; font-weight:bold; text-decoration:none;">
          GitHub Repository
        </a>
      </p>

      <!-- Project 2 -->
      <h2>Depression Severity Estimation System</h2>
      <p style="color:#ccc; font-size:16px; line-height:24px;">
          In this project, I developed a deep learning-based system for estimating depression severity through facial video
          analysis. Specifically, the OpenFace toolkit was adopted for facial detection and landmark tracking, from which I
          derived two feature sets: (1) Histogram of Displacement Range (HDR) features, capturing the velocity and magnitude of
          facial movements, and (2) Facial Action Unit (FAU) features, quantifying underlying muscle activations. These features
          were used to train a deep neural network (DNN) for depression severity estimation. Based on this model, I developed a
          cross-platform, web-based system where clients record a face video during a simulated semi-structured interview, and
          servers process the video to extract features and generate a severity estimate via the DNN. The system also allows users
          to review their assessment history and has been integrated into a longitudinal mental health monitoring platform.
      </p>

      <div style="margin-top:20px;">
        <iframe 
          src="https://drive.google.com/file/d/1w2P-__C1ilZuOtO31-H97V8rTIoeMaUC/preview"
          width="100%" height="430"
          style="border:none; border-radius:10px;">
        </iframe>
      </div>

      <p style="margin-top:15px;">
        ðŸ“„ <a href="https://drive.google.com/file/d/1-0_0ScU-eMWm1W4GUzUeB8IaMJEGlj2W/view"
              target="_blank"
              style="color:#ff8dd6; font-weight:bold; text-decoration:none;">
              Paper Link
            </a>
      </p>

      <!-- Project 3 -->
      <h2>Facial Expression Recognition System</h2>
      <p style="color:#ccc; font-size:16px; line-height:24px;">
        This project involved the development of a real-time emotion monitoring and alert system for hospital inpatients,
        leveraging deep learning for facial expression recognition. I trained a convolutional neural network (CNN) for emotion
        classification and integrated it with a pipeline that uses the Viola-Jones algorithm for robust face detection in video
        streams. The system is designed with a hardware module featuring indicator lights: a green light signifies the detection
        of a positive or neutral expression, while a red light alerts nursing staff to a negative expression. Experimental
        results confirmed that the system achieves high-accuracy, real-time emotion recognition, providing an efficient and
        automated solution for monitoring patient well-being.
      </p>

      <div style="margin-top:20px;">
        <iframe 
          src="https://drive.google.com/file/d/1BX7_Kp_RCRTqk06gpGyR0_INPpp3UHFf/preview"
          width="100%" height="430"
          style="border:none; border-radius:10px;">
        </iframe>
      </div>

      <p style="margin-top:15px;">
        ðŸ“„ <a href="https://drive.google.com/file/d/1pCbNmYr35-8ICzJ6ymLZyuXdAbS7IqSY/view"
              target="_blank"
              style="color:#ff8dd6; font-weight:bold; text-decoration:none;">
              Technical Report
            </a>
      </p>
      <!-- Project 4: Job Recommendation with AHP + K-means + GRNN -->
      <h2>Job Recommendation System Using AHP, K-means Clustering, and GRNN</h2>
      
      <p style="color:#ccc; font-size:16px; line-height:24px;">
        This project designed and implemented a three-tier job recommendation system to help high school students identify
        suitable summer employment. The system evaluates opportunities based on key criteria such as salary, comfort, personal
        development, and job fit. We integrated the Analytic Hierarchy Process (AHP) with K-means clustering, using AHP to
        assign optimal weights to each criterion (informed by student surveys) and clustering to categorize job types. A major
        innovation was using a Generalized Regression Neural Network (GRNN) to map student personality and capability
        assessments directly to AHP weights, eliminating the need for users to complete complex judgment matrices and ensuring a
        seamless one-time questionnaire experience. As the team leader, I spearheaded the system architecture, authored the
        majority of the code, and authored the majority of the conference paper.
      </p>
      
      <div style="margin-top:20px;">
        <iframe src="https://drive.google.com/file/d/15ludEZW1E72C4mNSkXg6LCTYWeGmmO34/preview" width="100%" height="430"
          allow="autoplay" style="border:none; border-radius:10px;">
        </iframe>
      </div>
      
      <p style="margin-top:15px;">
        ðŸ“„ <a href="https://drive.google.com/file/d/15ludEZW1E72C4mNSkXg6LCTYWeGmmO34/view" target="_blank"
          style="color:#ff8dd6; font-weight:bold; text-decoration:none;">
          Paper Link
        </a>
      </p>

    </div>

    <!-- ====================== GRAPHICS ====================== -->
    <div id="graphics" style="display:none;">

      <div class="section-title">Graphics Projects</div>

      <h2>Interactive Point Cloud Renderer</h2>
      <p style="color:#ccc; font-size:16px; line-height:24px;">
        Implemented an interactive renderer that allows keyboard-based navigation of large point clouds.
      </p>

      <div style="margin-top:20px;">
        <iframe 
          src="https://drive.google.com/file/d/12gy7agaKomazSc3OBTUCIUAgjl2UTEC7/preview"
          width="100%" height="430"
          style="border:none; border-radius:10px;">
        </iframe>
      </div>

      <h2>Spline-Based Roller Coaster Animation</h2>
      <p style="color:#ccc; font-size:16px; line-height:24px;">
        Rendered a roller-coaster scene where the camera follows a smooth spline path.
      </p>

      <div style="margin-top:20px;">
        <iframe 
          src="https://drive.google.com/file/d/1fn4lDrWZEO5jWUKySxar74pk4vqMfk3w/preview"
          width="100%" height="430"
          style="border:none; border-radius:10px;">
        </iframe>
      </div>

      <h2>Phong Shading & Recursive Reflection Rendering</h2>
      <p style="color:#ccc; font-size:16px; line-height:24px;">
        Implemented Phong shading and recursive ray-traced reflections.
      </p>

      <div style="display:flex; gap:20px; margin-top:20px;">
        <img 
          src="https://raw.githubusercontent.com/David-bit-jpg/davidwjl.github.io/main/Graphics-PhoneReflectiveRendering.jpg"
          style="flex:1; width:100%; height:350px; object-fit:cover; border-radius:10px; border:2px solid #333;">

        <img 
          src="https://raw.githubusercontent.com/David-bit-jpg/davidwjl.github.io/main/Graphics-PhoneReflectiveRendering2.jpg"
          style="flex:1; width:100%; height:350px; object-fit:cover; border-radius:10px; border:2px solid #333;">
      </div>

    </div>

    <!-- ====================== GAMES ====================== -->
    <div id="games" style="display:none;">

      <div class="section-title">Game Projects</div>

      <h2>ArtHouse / Engineer & Usability</h2>
      <p style="color:#ccc; font-size:16px; line-height:24px;">
        Art House is a narrative-driven 2D platformer that follows a daughterâ€™s journey to help her mother recover memories lost
        to Alzheimerâ€™s disease. As an engineer on the development team, I contributed to the design and implementation of the
        gameâ€™s core mechanics, including player movement, interaction systems, and environment-triggered narrative sequences. I
        developed several key visual and camera effectsâ€”such as distortion shaders, memory-flash transitions, and dynamic camera
        movementâ€”to support emotional storytelling and enhance gameplay clarity.
        In addition to gameplay programming, I conducted weekly playtesting sessions, authored structured feedback reports, and
        worked closely with designers, artists, and writers to refine level flow, puzzle pacing, and narrative coherence. My
        engineering contributions extended across prototype iteration, performance optimization, and bug triage, ensuring that
        the final release met production quality standards for a commercial Steam launch. This project strengthened my
        experience in Unity engine development, cross-disciplinary collaboration, and story-centric game design.

      </p>

      <div style="margin-top:20px;">
        <iframe 
          src="https://drive.google.com/file/d/1KScmZ7aOmShplPlk9bphW3lqmLQBgVtb/preview"
          width="100%" height="430"
          style="border:none; border-radius:10px;">
        </iframe>
      </div>

      <h2>Backroom Report</h2>
      <p style="color:#ccc; font-size:16px; line-height:24px;">
        Backroom Report is a 3D puzzleâ€“horror game where players navigate a labyrinth, solve environmental puzzles, collect
        photographic evidence, and evade a pursuing monster.
        As the primary engineer and systems designer, I built the core gameplay frameworkâ€”designing monster AI behavior, puzzle
        logic, and the full map editing pipeline. I also implemented key visual effects including shaders, post-processing
        filters, and the signature camera-flicker system that reacts dynamically to the monsterâ€™s presence.
      </p>

      <div style="margin-top:20px;">
        <iframe 
          src="https://drive.google.com/file/d/125vpuv-HlfzinRQCffLh4S625hTrVElg/preview"
          width="100%" height="430"
          style="border:none; border-radius:10px;">
        </iframe>
      </div>

      <h2>C++ Classic Games Collection</h2>
      <p style="color:#ccc; font-size:16px; line-height:24px;">
        Built multiple 2D and 3D classic games fully in C++, including Mario Kart, Pac-Man, Portal, and more.
        Through this advanced game programming course, I implemented core gameplay systems from the ground upâ€”covering
        rendering, input handling, audio, collision detection, physics interactions, and camera control. The coursework
        emphasized industry-standard techniques and essential mathematics for games, requiring each project to be programmed
        individually in C++. Across the semester, I developed several fully functional games and gained experience in designing
        engine-level architecture, debugging real-time systems, and applying critical reasoning to complex gameplay behaviors.
      </p>

      <h3 style="margin-top:25px; color:#ff8dd6;">Mario Kart (C++)</h3>
      <iframe 
        src="https://drive.google.com/file/d/1il1xPb6yM0c9UFixsioYsYU71GrKDQCY/preview"
        width="100%" height="430"
        style="border:none; border-radius:10px; margin-top:10px;">
      </iframe>

      <h3 style="margin-top:30px; color:#ff8dd6;">Pac-Man (C++)</h3>
      <iframe 
        src="https://drive.google.com/file/d/1eF-oJluB2-2JPIgCuwqFKD13hJ-r7N9e/preview"
        width="100%" height="430"
        style="border:none; border-radius:10px; margin-top:10px;">
      </iframe>

      <h3 style="margin-top:30px; color:#ff8dd6;">Portal (C++)</h3>
      <iframe 
        src="https://drive.google.com/file/d/1qS4XukgdEZarLYh1b77hXMcU1ffSkzfK/preview"
        width="100%" height="430"
        style="border:none; border-radius:10px; margin-top:10px;">
      </iframe>

      <p style="margin-top:20px;">
        ðŸ”— <a href="https://github.com/David-bit-jpg/ITP380-Games"
              target="_blank"
              style="color:#ff8dd6; font-weight:bold; text-decoration:none;">
            GitHub Repository
          </a>
      </p>

    </div>

  </div>



<script>
function showTab(tab) {
  document.getElementById("research").style.display = (tab === "research") ? "block" : "none";
  document.getElementById("graphics").style.display = (tab === "graphics") ? "block" : "none";
  document.getElementById("games").style.display = (tab === "games") ? "block" : "none";

  document.getElementById("researchTab").classList.remove("active");
  document.getElementById("graphicsTab").classList.remove("active");
  document.getElementById("gamesTab").classList.remove("active");

  document.getElementById(tab + "Tab").classList.add("active");
}
</script>

</body>
</html>
